{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Handwritten Chinese v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luzinsan/augmentation_and_regularizer/blob/main/Copy_of_Handwritten_Chinese_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HlCG5i4kDnS",
        "outputId": "d9edaf20-fa6e-44b0-a9ae-c4a8befb7c9a"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "\n",
        "!git clone https://github.com/AI-FREE-Team/Traditional-Chinese-Handwriting-Dataset.git\n",
        "OutputFolder = '/content/Handwritten_Data'\n",
        "!rm -rf '/content/Handwritten_Data'"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Traditional-Chinese-Handwriting-Dataset'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 174 (delta 75), reused 22 (delta 6), pack-reused 18\u001b[K\n",
            "Receiving objects: 100% (174/174), 77.40 MiB | 25.11 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIMzxCtACUxL"
      },
      "source": [
        "SIZE = 150 # рассматриваем 150 классов"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEsfKRwc_bg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a24fc8-dc44-40bc-f65c-3732225c81ed"
      },
      "source": [
        "CompressedFiles = []\n",
        "\n",
        "os.chdir('/content/Traditional-Chinese-Handwriting-Dataset/data')\n",
        "\n",
        "for item in os.listdir():  \n",
        "  if item.endswith('.zip'): # Check for \".zip\" extension.\n",
        "    file_path = os.path.abspath(item) # Get full path of the compressed file. \n",
        "    CompressedFiles.append(file_path)\n",
        "\n",
        "for file in CompressedFiles:     \n",
        "  # Construct a ZipFile object with the filename, and then extract it.\n",
        "  zip_ref = zipfile.ZipFile(file).extractall(OutputFolder) \n",
        "  \n",
        "  source_path = OutputFolder + '/cleaned_data(50_50)'\n",
        "  img_list = os.listdir(source_path)\n",
        "\n",
        "  for img in img_list:\n",
        "      shutil.move(source_path + '/' + img, OutputFolder) # Move a file to another location. \n",
        "  \n",
        "  shutil.rmtree(OutputFolder + '/cleaned_data(50_50)') \n",
        "  #print(f'Decompress successfully {file} ......')\n",
        "  #print( 'Moving images according to traditional Chinese characters......' )\n",
        "\n",
        "ImageList = os.listdir(OutputFolder)\n",
        "ImageList = [img for img in ImageList if len(img)>1]\n",
        "WordList = list(set([w.split('_')[0] for w in ImageList]))[:SIZE]\n",
        "\n",
        "for w in WordList:\n",
        "  try:\n",
        "    os.chdir(OutputFolder) # Change the current working directory to OutputPath.\n",
        "    os.mkdir(w) # Create the new word folder in OutputPath.\n",
        "    MoveList = [img for img in ImageList if w in img]\n",
        "                \n",
        "  except: \n",
        "    os.chdir(OutputFolder)\n",
        "    MoveList = [img for img in ImageList if w in img ]\n",
        "  \n",
        "  finally:            \n",
        "    for img in MoveList:\n",
        "      old_path = OutputFolder + '/' + img\n",
        "      new_path = OutputFolder + '/' + w + '/' + img\n",
        "      shutil.move( old_path, new_path )\n",
        "\n",
        "print( 'Data Deployment completed.' )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Deployment completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtJidZSSed2C"
      },
      "source": [
        "a=0\n",
        "b=0\n",
        "\n",
        "for item in os.listdir(OutputFolder):\n",
        "  if (os.path.isdir(item)):  \n",
        "    a += 1\n",
        "    for i in os.listdir(OutputFolder + '/' + item):\n",
        "      b +=1\n",
        "\n",
        "#print ('Всего: ' + str(a) + ' слов (папка) / Всего: ' + str(b) + ' образцов')\n",
        "#print ('В среднем каждое слово содержит: ' + str (b / a) + ' образцов')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BZsXzH5dSZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137bfc30-1f96-4b9b-f8e7-7e18ddd90de3"
      },
      "source": [
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.1)\n",
        "train_dataset = image_generator.flow_from_directory(str(OutputFolder), class_mode='sparse', batch_size=10, target_size=(50, 50), subset='training')\n",
        "valid_dataset = image_generator.flow_from_directory(str(OutputFolder), class_mode='sparse', batch_size=10, target_size=(50, 50), subset='validation')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7050 images belonging to 150 classes.\n",
            "Found 735 images belonging to 150 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sodcd863Adst"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EGnVs1JIdcD"
      },
      "source": [
        "IMG_SIZE = 30\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  tf.keras.layers.Rescaling(1./255)\n",
        "])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5yTllMEdfrp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "cb4f750c-f4ba-4d99-fdb8-afb269fb7cbb"
      },
      "source": [
        "for image_b, label_b in train_dataset:\n",
        "  #print(\"Image batch shape: \", image_b.shape)\n",
        "  #print(\"Label batch shape: \", label_b.shape)\n",
        "  plt.imshow(image_b[1])\n",
        "  image_batch = resize_and_rescale(image_b)\n",
        "  \n",
        "  label_batch = label_b\n",
        "  #print(label_batch)\n",
        "  break"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etnfw23vswSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "600ef016-d66f-49e9-f0e1-4550d68236df"
      },
      "source": [
        "plt.imshow(image_batch[1])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7135654090>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WucSLXxZdpuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98626967-454b-4db0-813c-581694344b30"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=16,  kernel_size=3, activation='relu', padding= 'same' , input_shape=(50,50,3)),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "  tf.keras.layers.Conv2D(filters=32,  kernel_size=3, activation='relu', padding= 'same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "  tf.keras.layers.Conv2D(filters=64,  kernel_size=3, activation='relu', padding= 'same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "  tf.keras.layers.Conv2D(filters=128,  kernel_size=2, activation='relu', padding= 'same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
        "  tf.keras.layers.Conv2D(filters=256,  kernel_size=2, activation='relu', padding= 'same'),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "  #tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(SIZE, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 50, 50, 16)        448       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 25, 25, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 25, 25, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 12, 12, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 6, 6, 128)         32896     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 3, 3, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 3, 3, 256)         131328    \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               1180160   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 150)               76950     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,444,918\n",
            "Trainable params: 1,444,918\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKYthET16Sez"
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(1.8, decay_steps = 705*5, decay_rate = 0.1, staircase = False)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWAuDixXdzYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffbf5a3-dc18-49d0-9759-91eedd8ff655"
      },
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adadelta(lr_schedule),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "EPOCHS = 20\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=valid_dataset,\n",
        "                    epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "705/705 [==============================] - 10s 13ms/step - loss: 5.4838 - accuracy: 0.0356 - val_loss: 4.2952 - val_accuracy: 0.0857\n",
            "Epoch 2/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 2.4000 - accuracy: 0.3989 - val_loss: 1.8732 - val_accuracy: 0.5020\n",
            "Epoch 3/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 1.0923 - accuracy: 0.7111 - val_loss: 1.0705 - val_accuracy: 0.7510\n",
            "Epoch 4/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 0.7028 - accuracy: 0.8281 - val_loss: 0.9492 - val_accuracy: 0.7578\n",
            "Epoch 5/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 0.5069 - accuracy: 0.8774 - val_loss: 0.8544 - val_accuracy: 0.8190\n",
            "Epoch 6/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 0.3963 - accuracy: 0.9099 - val_loss: 0.7396 - val_accuracy: 0.8463\n",
            "Epoch 7/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 0.3280 - accuracy: 0.9323 - val_loss: 0.6404 - val_accuracy: 0.8612\n",
            "Epoch 8/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 0.2656 - accuracy: 0.9479 - val_loss: 0.7991 - val_accuracy: 0.8476\n",
            "Epoch 9/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 0.2388 - accuracy: 0.9553 - val_loss: 0.6747 - val_accuracy: 0.8667\n",
            "Epoch 10/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 0.1948 - accuracy: 0.9650 - val_loss: 0.7105 - val_accuracy: 0.8816\n",
            "Epoch 11/20\n",
            "705/705 [==============================] - 9s 13ms/step - loss: 0.1708 - accuracy: 0.9706 - val_loss: 0.7589 - val_accuracy: 0.8816\n",
            "Epoch 12/20\n",
            "579/705 [=======================>......] - ETA: 1s - loss: 0.1784 - accuracy: 0.9693"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY8w5Bk0duJZ"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([min(plt.ylim()),max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}